{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stuff\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "\n",
    "# Visual stuff\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# VIP STUFF!\n",
    "from dask.distributed import Client\n",
    "client = Client()  # start distributed scheduler locally.  Launch dashboard\n",
    "\n",
    "# Warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read samples from data_gen folder\n",
    "samples = dd.read_csv('../data_gen/samples/*.part',\n",
    "                               dtype={'icd_code': 'object'})\n",
    "\n",
    "# Read core admissions\n",
    "core_admissions = dd.read_csv('../mimic-iv-0.4/core/admissions.csv',\n",
    "                              usecols=['subject_id','hadm_id','admittime']\n",
    "                             ).compute() # Move into memory(very small, no problem my friend)\n",
    "# Read samples with lab\n",
    "samples_with_lab = dd.read_csv('../data_gen/samples_with_lab/*.part', \n",
    "                               dtype={'value': 'object'}) # small enough my friend, but no\n",
    "\n",
    "# Read samples with chartevents\n",
    "samples_chart = dd.read_csv('../data_gen/samples_with_chart/*.part').compute()\n",
    "\n",
    "# drop nan values from samples with lab\n",
    "samples_with_lab = samples_with_lab.dropna(subset=['label']).compute()\n",
    "\n",
    "# Lab measures to include, select top 35 avaiable and remove some\n",
    "lab_value_list = samples_with_lab.label.value_counts().index[0:35].values.tolist()\n",
    "\n",
    "# Ignore this warning\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "# Speed-up by pre-computing tables\n",
    "pre_gen_lab_tables = dict([(val, samples_with_lab[samples_with_lab.label.str.contains(val)].sort_values(by='charttime') ) for val in lab_value_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure each lab feature only has one unit type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creatinine units : ['mg/dL', 'mg/mg', 'mg/g', 'Ratio', 'mg/24hr', 'mL/min']\n",
      "Highest occurrence:  mg/dL\n",
      "\n",
      "\n",
      "Hemoglobin units : ['g/dL', '%']\n",
      "Highest occurrence:  g/dL\n",
      "\n",
      "\n",
      "Phosphate units : ['mg/dL', nan, '/hpf']\n",
      "Highest occurrence:  mg/dL\n",
      "\n",
      "\n",
      "MCHC units : ['g/dL', '%']\n",
      "Highest occurrence:  g/dL\n",
      "\n",
      "\n",
      "MCH units : ['pg', 'g/dL', '%']\n",
      "Highest occurrence:  pg\n",
      "\n",
      "\n",
      "RDW units : ['fL', '%']\n",
      "Highest occurrence:  %\n",
      "\n",
      "\n",
      "pH units : ['units', nan]\n",
      "Highest occurrence:  units\n",
      "\n",
      "\n",
      "PT units : [nan, 'sec']\n",
      "Highest occurrence:  sec\n",
      "\n",
      "\n",
      "L units : ['%', 'K/uL', 'IU/L', nan, 'mmol/L', 'log10 IU/mL', 'mg/dL', 'log10 cop/mL', 'mg/L', 'Ratio', 'U/mL', '#/uL', 'IU/mL', 'U/L', 'U', 'log10 copies/mL', 'mIU/mL']\n",
      "Highest occurrence:  IU/L\n",
      "\n",
      "\n",
      "H units : ['units', 'g/dL', '%', 'pg', nan, '#/lpf', 'log10 IU/mL', 'uIU/mL', 'mg/dL', 'ng/mL', 'log10 cop/mL', 'Ratio', 'pg/mL', 'U/mL', 'IU/mL', '+/-', 'mIU/mL', 'U', 'log10 copies/mL', 'nmol/L', 'umol/L', 'mg/L', 'mmol/L', 'ug/dL']\n",
      "Highest occurrence:  %\n",
      "\n",
      "\n",
      "I units : ['%', nan, 'mg/dL', 'ug/dL', 'ng/mL', 'log10 cop/mL', 'units', 'MPL', 'GPL', 'U', 'log10 copies/mL', 'U/mL']\n",
      "Highest occurrence:  ng/mL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check and handle multiple units, keep one with most frequent counts.\n",
    "for item in list(pre_gen_lab_tables.keys()):\n",
    "    unique_keys = pre_gen_lab_tables[item].valueuom.unique().tolist()\n",
    "    if len(unique_keys) > 1:\n",
    "        print(item, \"units :\", unique_keys)\n",
    "        highest_oc_unit = pre_gen_lab_tables[item].valueuom.value_counts().index[0]\n",
    "        print('Highest occurrence: ', pre_gen_lab_tables[item].valueuom.value_counts().index[0]) \n",
    "        print('\\n')\n",
    "        # Only keep highest occurrence unit\n",
    "        pre_gen_lab_tables[item] = pre_gen_lab_tables[item][pre_gen_lab_tables[item].valueuom==highest_oc_unit]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion numbers to get standard units\n",
    "lbs_conv = 0.45359237 # to kg\n",
    "inch_conv =  0.39370079 # to cm\n",
    "\n",
    "# Given a hadm_id find BMI from samples with chart, height and weight is required\n",
    "def BMI_find(hadm_id):\n",
    "    p_data = samples_chart[samples_chart.hadm_id==hadm_id]\n",
    "    h_inches =  p_data[p_data.label=='Height']\n",
    "    h_cm =  p_data[p_data.label=='Height (cm)']\n",
    "    w_kg =  p_data[p_data.label=='Admission Weight (Kg)']\n",
    "    w_lbs = p_data[p_data.label=='Admission Weight (lbs.)']\n",
    "    \n",
    "    # Ensure that there is at least height and weight in standard units or convert from lollipops per unicorn(american)\n",
    "    if ( (len(h_inches) > 0) | (len(h_cm) > 0) ) & ( (len(w_kg) > 0) | (len(w_lbs) > 0) ):\n",
    "        if len(w_kg) > 0:\n",
    "            weight = w_kg.value.values[0]\n",
    "        else:\n",
    "            weight = w_lbs.value.values[0] / lbs_conv \n",
    "        if len(h_cm) > 0:\n",
    "            height = h_cm.value.values[0] / 100\n",
    "        else: \n",
    "            height = (h_inches.value.values[0] / inch_conv) / 100\n",
    "        \n",
    "        BMI = float(weight / (height**2))\n",
    "        # Return BMI, sanity check first, 11-98, others are clearly transcribed wrong(manually checked)\n",
    "        if (BMI<98) & (BMI>11):\n",
    "            return BMI\n",
    "    # Failed to generate BMI\n",
    "    return float('NaN')\n",
    "    \n",
    "\n",
    "# Return value for some lab feature for a hadm_id\n",
    "def lab_label(label,hadm_id):\n",
    "    temp = pre_gen_lab_tables.get(label)\n",
    "    val = get_earliest_val(temp[temp.hadm_id==hadm_id])\n",
    "    return val\n",
    "   \n",
    "# Get the earliest\n",
    "def get_earliest_val(sub_df):\n",
    "    if len(sub_df) < 1:\n",
    "        return float('NaN')\n",
    "    else:\n",
    "        for item in sub_df[['value']].values:\n",
    "            try:\n",
    "                rtr = float(item)\n",
    "                return rtr\n",
    "            except:\n",
    "                continue\n",
    "        return float('NaN')\n",
    "    \n",
    "\n",
    "# Return times previously admitted\n",
    "def times_prev_admitted(subject_id,hadm_id,admittime):\n",
    "    return (core_admissions[\n",
    "        (core_admissions.subject_id==subject_id) & \n",
    "        (core_admissions.hadm_id!=hadm_id) &\n",
    "        (core_admissions.admittime < admittime) \n",
    "        ]).shape[0]\n",
    "    \n",
    "# Return array with new feature\n",
    "def transform(df):\n",
    "        return [\n",
    "            df['hadm_id'],\n",
    "            ((pd.Timestamp(df['dischtime'])-pd.Timestamp(df['admittime'])).days),\n",
    "            float((df['anchor_age'] * 365 + (pd.Timestamp(df['admittime'])-pd.Timestamp(str(df['anchor_year']))).days)/365.25),\n",
    "            times_prev_admitted(df.subject_id,df.hadm_id,df.admittime),\n",
    "            BMI_find(df['hadm_id'])\n",
    "        ] + [lab_label(val,df['hadm_id']) for val in lab_value_list]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run transform function to generate features\n",
    "res = samples.apply(transform, axis=1, meta=(None, 'timedelta64[ns]'))\n",
    "# Add to temporary dataframe\n",
    "dataframe_temp = dd.from_pandas(pd.DataFrame(res.compute().to_list(),\n",
    "                                             columns=['hadm_id',\n",
    "                                                        'length_of_stay(days)', # days\n",
    "                                                        'age_at_admission',\n",
    "                                                        'times_prev_admitted',\n",
    "                                                        'BMI'\n",
    "                                                     ]+lab_value_list\n",
    "                                            ), npartitions=samples.npartitions).compute()\n",
    "# Merge temporary dataframe with samples(it already contains some features)\n",
    "samples = dd.merge(samples,dataframe_temp,on=['hadm_id'],how='inner').compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include only some columns\n",
    "feature_names = ['age_at_admission',\n",
    "                 'gender','language',\n",
    "                 'ethnicity',\n",
    "                 'insurance',\n",
    "                 'seq_num',\n",
    "                 'marital_status',\n",
    "                 'times_prev_admitted',\n",
    "                 'length_of_stay(days)',\n",
    "                 'BMI']+lab_value_list\n",
    "samples = samples[feature_names+['hospital_expire_flag']] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process and write data set to data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column, unique values in column:\n",
      "age_at_admission 13019\n",
      "gender 2\n",
      "language 2\n",
      "ethnicity 8\n",
      "insurance 3\n",
      "seq_num 27\n",
      "marital_status 4\n",
      "times_prev_admitted 82\n",
      "length_of_stay(days) 149\n",
      "BMI 3418\n",
      "Glucose 496\n",
      "Potassium 165\n",
      "Sodium 163\n",
      "Chloride 141\n",
      "Bicarbonate 49\n",
      "Anion Gap 47\n",
      "Creatinine 359\n",
      "Urea Nitrogen 459\n",
      "Magnesium 53\n",
      "Hematocrit 420\n",
      "Hemoglobin 152\n",
      "Platelet Count 763\n",
      "Phosphate 138\n",
      "Calcium, Total 117\n",
      "White Blood Cells 540\n",
      "MCHC 118\n",
      "MCH 260\n",
      "MCV 78\n",
      "Red Blood Cells 485\n",
      "RDW 178\n",
      "pH 113\n",
      "PTT 828\n",
      "PT 849\n",
      "INR(PT) 0\n",
      "Specimen Type 0\n",
      "L 1046\n",
      "H 469\n",
      "I 165\n",
      "RDW-SD 522\n",
      "pO2 469\n",
      "Calculated Total CO2 60\n",
      "Base Excess 57\n",
      "pCO2 123\n",
      "Bilirubin, Total 249\n",
      "Alanine Aminotransferase (ALT) 0\n",
      "hospital_expire_flag 2\n"
     ]
    }
   ],
   "source": [
    "# Check unique values for all columns\n",
    "print('Column, unique values in column:')\n",
    "for i, col in enumerate(samples.columns):\n",
    "    print(col, samples[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoded following columns(name):\n",
      "gender\n",
      "language\n"
     ]
    }
   ],
   "source": [
    "# Label encoding(binary)\n",
    "print('Label encoded following columns(name):')\n",
    "for column in samples.columns:\n",
    "    unique_col_values = samples[column].nunique()\n",
    "    if (unique_col_values == 2 and column!='hospital_expire_flag'):\n",
    "        print(column)\n",
    "        temp_new = le.fit_transform(samples[column].astype('category'))\n",
    "        samples.drop(labels=[column], axis=\"columns\", inplace=True)\n",
    "        samples[column] = temp_new\n",
    "        \n",
    "# Rename to as only options are english or ? \n",
    "samples = samples.rename(columns={'language':'language_english'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['marital_status_DIVORCED', 'marital_status_MARRIED',\n",
      "       'marital_status_SINGLE', 'marital_status_WIDOWED'],\n",
      "      dtype='object')\n",
      "Index(['insurance_Medicaid', 'insurance_Medicare', 'insurance_Other'], dtype='object')\n",
      "Index(['ethnicity_AMERICAN INDIAN/ALASKA NATIVE', 'ethnicity_ASIAN',\n",
      "       'ethnicity_BLACK/AFRICAN AMERICAN', 'ethnicity_HISPANIC/LATINO',\n",
      "       'ethnicity_OTHER', 'ethnicity_UNABLE TO OBTAIN', 'ethnicity_UNKNOWN',\n",
      "       'ethnicity_WHITE'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ethnicity_AMERICAN INDIAN/ALASKA NATIVE', 'ethnicity_ASIAN',\n",
       "       'ethnicity_BLACK/AFRICAN AMERICAN', 'ethnicity_HISPANIC/LATINO',\n",
       "       'ethnicity_OTHER', 'ethnicity_UNABLE TO OBTAIN', 'ethnicity_UNKNOWN',\n",
       "       'ethnicity_WHITE', 'insurance_Medicaid', 'insurance_Medicare',\n",
       "       'insurance_Other', 'marital_status_DIVORCED', 'marital_status_MARRIED',\n",
       "       'marital_status_SINGLE', 'marital_status_WIDOWED', 'age_at_admission',\n",
       "       'seq_num', 'times_prev_admitted', 'length_of_stay(days)', 'BMI',\n",
       "       'Glucose', 'Potassium', 'Sodium', 'Chloride', 'Bicarbonate',\n",
       "       'Anion Gap', 'Creatinine', 'Urea Nitrogen', 'Magnesium', 'Hematocrit',\n",
       "       'Hemoglobin', 'Platelet Count', 'Phosphate', 'Calcium, Total',\n",
       "       'White Blood Cells', 'MCHC', 'MCH', 'MCV', 'Red Blood Cells', 'RDW',\n",
       "       'pH', 'PTT', 'PT', 'INR(PT)', 'Specimen Type', 'L', 'H', 'I', 'RDW-SD',\n",
       "       'pO2', 'Calculated Total CO2', 'Base Excess', 'pCO2',\n",
       "       'Bilirubin, Total', 'Alanine Aminotransferase (ALT)',\n",
       "       'hospital_expire_flag', 'gender', 'language_english'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OneHotEncoding\n",
    "one_hot_encode_cols = ['marital_status','insurance', 'ethnicity']\n",
    "\n",
    "for i, col in enumerate(one_hot_encode_cols):\n",
    "    print(pd.get_dummies(samples[col],prefix=col,dtype=int).columns)\n",
    "    \n",
    "# Prepare index join for axis 1\n",
    "samples = samples.reset_index(drop=True)\n",
    "\n",
    "# Encode\n",
    "for i, col in enumerate(one_hot_encode_cols):\n",
    "    temp = pd.get_dummies(samples[col],prefix=col,dtype=int)\n",
    "    # drop unable to obtain and unknown (for any string)\n",
    "    samples = pd.concat([temp,samples],axis=1)\n",
    "    \n",
    "# Drop columns which were encoded\n",
    "samples = samples.drop(columns=one_hot_encode_cols)\n",
    "    \n",
    "samples.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  ['ethnicity_UNKNOWN', 'ethnicity_UNABLE TO OBTAIN', 'ethnicity_OTHER', 'insurance_Other']\n"
     ]
    }
   ],
   "source": [
    "# Drop all columns containing these strings\n",
    "strings_drop = ['unknown','?','unable to obtain','other']\n",
    "cols_to_drop = []\n",
    "for item in strings_drop:\n",
    "    cols_to_drop = cols_to_drop +[col_name for col_name in \n",
    "     [col for col in samples.columns] \n",
    "     if col_name.lower().find(item.lower()) > -1]\n",
    "samples = samples.drop(labels=cols_to_drop, axis=1)\n",
    "print('dropped: ', cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "dd.from_pandas(samples, npartitions=32).to_csv('../data_gen/samples_transformed', index=False,)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
