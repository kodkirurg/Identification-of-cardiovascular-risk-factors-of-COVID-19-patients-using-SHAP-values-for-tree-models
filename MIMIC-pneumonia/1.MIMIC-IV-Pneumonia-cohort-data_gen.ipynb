{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data stuff\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Visual stuff\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# VIP STUFF!\n",
    "from dask.distributed import Client\n",
    "client = Client()  # start distributed scheduler locally.  Launch dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-IV-V0.4\n",
    "- Only ICU, HOSP and core available so far.\n",
    "\n",
    "\n",
    "# Outcomes\n",
    "Mortality prediction\n",
    "\n",
    "\n",
    "# Cohort\n",
    "All admitted patients that were diagnosed with any kind of pneumonia during their stay.\n",
    "\n",
    "## Codes for pneumonia\n",
    "ICD-10: J12-J18\n",
    "\n",
    "ICD-9: 480-486, 770.0\n",
    "\n",
    "## seq_num\n",
    "The priority assigned to the diagnoses. The priority can be interpreted as a ranking of which diagnoses are “important”, but many caveats to this broad statement exist. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cohort selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core information about patients admitted to the hospital(demographics)\n",
    "core_patients = dd.read_csv('../mimic-iv-0.4/core/patients.csv',\n",
    "                            usecols=['subject_id','gender','anchor_age','anchor_year','anchor_year_group'])\n",
    "core_admissions = dd.read_csv('../mimic-iv-0.4/core/admissions.csv',\n",
    "                              usecols=['subject_id','hadm_id','admittime','dischtime','insurance','language','marital_status','ethnicity','hospital_expire_flag']\n",
    "                             )\n",
    "\n",
    "# Generate dataset for core information about all admissions\n",
    "dataset = dd.merge(core_admissions,core_patients, on='subject_id', how='left')\n",
    "\n",
    "# diagnosed admissions with penumonia\n",
    "hosp_diagnoses_icd = dd.read_csv('../mimic-iv-0.4/hosp/diagnoses_icd.csv')\n",
    "\n",
    "# Pneumonia codes\n",
    "icd_9_codes_pne = tuple(['480','481','482','483','484','485','486','7700'])\n",
    "icd_10_codes_pne = tuple(['J12','J13','J14','J15','J16','J17','J18'])\n",
    "\n",
    "# All diagnoses with icd_v_9 codes\n",
    "diagnoses_icd_9 = hosp_diagnoses_icd[hosp_diagnoses_icd.icd_version==9] \n",
    "# All diagnoses with icd_v_10 codes\n",
    "diagnoses_icd_10 = hosp_diagnoses_icd[hosp_diagnoses_icd.icd_version==10] \n",
    "\n",
    "# Extract pneunonia subjects from both versions and merge\n",
    "viral_pneumonia_subjects_v9 = diagnoses_icd_9[diagnoses_icd_9.icd_code.str.startswith(icd_9_codes_pne)]\n",
    "viral_pneumonia_subjects_v10 = diagnoses_icd_10[diagnoses_icd_10.icd_code.str.startswith(icd_10_codes_pne)]\n",
    "viral_pneumonia_subjects = viral_pneumonia_subjects_v9.merge(viral_pneumonia_subjects_v10, how='outer')\n",
    "\n",
    "# remove patients from dataset which were not diagnossed with penumonia\n",
    "dataset = dd.merge(dataset, viral_pneumonia_subjects, on= ['subject_id', 'hadm_id'],how='right')\n",
    "\n",
    "# Drop duplicates (multiple diagnoses for same admission), keep highest seq?\n",
    "dataset = dataset.compute().sort_values(by='seq_num').drop_duplicates(keep='first',subset=['hadm_id'])\n",
    "\n",
    "# save some information\n",
    "died_dataset = dataset[dataset.hospital_expire_flag==1].shape[0] # 1 = death\n",
    "lived_dataset =  dataset[dataset.hospital_expire_flag==0].shape[0] # 0 = survived \n",
    "rows_dataset = dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information and write to data_gen folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total in final cohort: 19941\n",
      "died: 2009\n",
      "lived: 17932\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Print some information\n",
    "print(\"total in final cohort:\", rows_dataset)\n",
    "print(\"died:\", died_dataset)\n",
    "print(\"lived:\",  lived_dataset)\n",
    "\n",
    "# Convert to dask dataframe from pandas\n",
    "dataset = dd.from_pandas(dataset, npartitions=4)\n",
    "\n",
    "# Write to data_gen folder\n",
    "dataset.to_csv('../data_gen/samples', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data sets for labevents and chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only hadm_ids\n",
    "samples_hadm_ids = dataset[['hadm_id']].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labevents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read labevents\n",
    "hosp_labevents = dd.read_csv('../mimic-iv-0.4/hosp/labevents.csv',\n",
    "                              usecols=['hadm_id','value','valueuom','itemid','charttime']\n",
    "                             )\n",
    "# ensure correct type on hadm_id\n",
    "hosp_labevents = hosp_labevents.dropna(subset=['hadm_id'])\n",
    "hosp_labevents.hadm_id = hosp_labevents.hadm_id.astype('int64')\n",
    "# read items(description of labevents)\n",
    "hosp_d_labitems = dd.read_csv('../mimic-iv-0.4/hosp/d_labitems.csv',\n",
    "                              usecols=['itemid','label','fluid','category']\n",
    "                             ).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Merge and write to files\n",
    "samples_with_lab = dd.merge(samples_hadm_ids, hosp_labevents, how='left',on='hadm_id', npartitions=32)\n",
    "samples_with_lab = dd.merge(hosp_d_labitems, samples_with_lab,how='right',on='itemid', npartitions=32)\n",
    "samples_with_lab.to_csv('../data_gen/samples_with_lab', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chartevents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Read charts and items for charts\n",
    "icu_chartevents = dd.read_csv('../mimic-iv-0.4/icu/chartevents.csv',\n",
    "                              usecols=['hadm_id','charttime','itemid','value'] )\n",
    "icu_d_items = dd.read_csv('../mimic-iv-0.4/icu/d_items.csv',usecols=['itemid','label']).compute()\n",
    "\n",
    "# Merge events with items of events(add description)\n",
    "samples_with_chart  = dd.merge(icu_chartevents, icu_d_items, how='left' ,on='itemid')\n",
    "\n",
    "# Remove all rows withouth these labels\n",
    "selections = ['Admission Weight (Kg)','Admission Weight (lbs.)','Height','Height (cm)']\n",
    "samples_with_chart = samples_with_chart[samples_with_chart.label.isin(selections)]\n",
    "\n",
    "# Merge onto sample group and drop nan values\n",
    "samples_with_chart  = dd.merge(samples_with_chart, samples_hadm_ids , how='right', on='hadm_id')\n",
    "samples_with_chart = samples_with_chart.dropna(subset=['value'])\n",
    "samples_with_chart.to_csv('../data_gen/samples_with_chart', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
